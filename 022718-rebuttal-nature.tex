% Title:    A LaTeX Template For Responses To a Referees' Reports
% Author:   Petr Zemek <s3rvac@gmail.com>
% Homepage: https://blog.petrzemek.net/2016/07/17/latex-template-for-responses-to-referees-reports/
% License:  CC BY 4.0 (https://creativecommons.org/licenses/by/4.0/)
\documentclass[11pt]{article}


\marginparwidth 0pt
\oddsidemargin  0pt
\evensidemargin  0pt
\marginparsep 0pt
\topmargin   -0.25in 
\textwidth   6.5in
\textheight  9.0in
% Allow Unicode input (alternatively, you can use XeLaTeX or LuaLaTeX)
\usepackage[utf8]{inputenc}
\usepackage{color,nima}
\newcommand{\outNim}[1]{}

\usepackage{microtype,xparse,tcolorbox}
\newenvironment{reviewer-comment }{}{}
\tcbuselibrary{skins}
\tcbuselibrary{breakable}
\tcolorboxenvironment{reviewer-comment }{empty,
  left = 1em, top = 1ex, bottom = 1ex,
  borderline west = {2pt} {0pt} {black!20},breakable
}
\ExplSyntaxOn
\NewDocumentEnvironment {response} { +m O{black!20} } {
  \IfValueT {#1} {
    \begin{reviewer-comment~}
      \setlength\parindent{2em}
      \noindent
      \ttfamily #1
    \end{reviewer-comment~}
  }
  \par\noindent\ignorespaces
} { \bigskip\par }

% \NewDocumentEnvironment {response} { +m O{black!20} } {
%   \IfValueT {#1} {
%     \begin{tcolorbox}[breakable]
%         \setlength\parindent{2em}
%       \noindent
%       \ttfamily #1
%     \end{tcolorbox}
  
%     % \begin{reviewer-comment~}
%     %   \setlength\parindent{2em}
%     %   \noindent
%     %   \ttfamily #1
%     % \end{reviewer-comment~}
%   }
%   \par\noindent\ignorespaces
% } { \bigskip\par }


\NewDocumentCommand \Reviewer { m } {
  \section*{Comments~by~Reviewer~#1}
}
\ExplSyntaxOff
%\AtBeginDocument{\maketitle\thispagestyle{empty}\noindent}

% You can get probably get rid of these definitions:
\newcommand\meta[1]{$\langle\hbox{#1}\rangle$}
\newcommand\PaperTitle[1]{``\textit{#1}''}

\title{Statement on the Revision of \meta{Paper ID} \\
  Based on the Referees' Report}
\author{Author1 \and Author2 \and Author3}
\date{\today}
\usepackage{setspace}
% \onehalfspacing
 \linespread{1.5}

\begin{document}


% This statement concerns our revision of the \meta{Paper ID} paper,
% entitled \PaperTitle{\meta{Paper Title}}, based on the referees' report.
\subsection*{TODO}

 \linespread{1}

\begin{enumerate}
    \item Code online
    % \item Complexity details
    % \item Phase graph for 3D random geometric graphs.   
    \item Transition point not scaling with size. Discuss correct choice of $N,L$. 
    % \item curvature  
    \item Discuss why relaxation time of ELI is not peaked
    \item Calculate finite size scaling of transition region. 
\end{enumerate}

 \linespread{1.5}
\Reviewer{\#1}

\begin{response}{
Characterizing the network geometry of networks is a topics of significant scientific interest and it is fundamental for understanding the architecture principles of the connectome and for the designing 3D integrated circuits. This manuscript provides a theoretical framework and an algorithm applicable to any network topology to characterize the network geometry in 3D when links have a give thickness and link crossing are forbidden.
While the optimization problem addressed by this manuscript is NP hard, the proposed algorithms are able to find the energetically favourable local minima and avoid link crossing. The conducted investigation over a large variety of networks reveals an universal phase transition between a weakly interacting phase and a strongly interacting phase as a function of the links thickness. The network physical properties are tested by applying external forces and monitoring the network response. It is found that the observed phase transition corresponds to a solid and fluid gel-like response to stress.
The work is highly innovative and very important to reveal the network geometry underlying complex networks. As such it has a wide realm of applications and it will be important for a large variety of disciplines. I believe that this work together with the rich Supplementary Material are suitable for publication in Nature.
However I would like to raise few comments that the Authors might consider to address for their resubmitted revealing the wide range of questions that such work can generate.
}
We thank the referee for their gracious comments. 

\end{response}

\begin{response}{
1) First of all I believe that a freely available codes would be very important for busting the research in this field. Are the Authors thinking of publishing their code?
}
We fully agree. We are , therefore, sharing 
all of the simulation source code in Python, together with an example code in Jupyter notebook will be on github. 
A web-based tool to visualize and interact with the simulations in 3D is also available on github. 
%{\color{red} Include URL?} 
\end{response}
\begin{response}{
2) An analysis of the computational complexity of the algorithm would be relevant, how does the time of computation and the memory needed to store these physical networks scale with the network parameters?
}
This is, indeed, a key point. 
We therefore added Sec. SI 8.C gives a preliminary analysis of the time complexity of the algorithm which we would like to supplement by the following.  %({\color{red} SI 8.C is actually only for finding crossings, but the same holds for the full algorithm}). 
%The same computation is also used to optimize the force calculations in the weakly interacting regime and a slightly more general version is used to partition the space in the strongly interacting phase.
% For simulations we have to break links down into segments. 
Briefly, if each link had $s$ segments, the  complexity of the elastic forces will be $O(sL)$.
The brute-force complexity of node repulsion is $O(N^2)$ and link repulsion $O(s^2L^2)$.
Since for a connected network $L\geq N-1$ and $s>1$, the complexity is mostly due to link repulsion. 
We can reduce this complexity by realizing that we only need short-range link repulsion to avoid crossings, allowing us to partition the space into cells of size $ar_L$ with $10>a>2$ and calculate link crossings in these cells only, as the repulsive forces between links farther than $ar_L$ will be exponentially small.
To be specific, if the layout is broken into $k$ cubic cells, each cell contains $sL/k$ link segments, on average, and so the total number of pair interactions has complexity
$O(k\times s^2L^2/k^2 ) = O(s^2L^2/k)$ (SI 8.C). 
A fixed minimum number of cells, $k$, is desirable at early stages as links may be very densely packed and a cell of size $ar_L$ may contain too many segments, resulting in memory shortage from storing the $O(s^2L^2)$ interaction matrix in the worst case. 
When the system has opened up sufficiently, we can break the layout into cells of fixed size $ar_L$ and index which segments of which links cross each cell. 
The indexing is $O(sL)$ and is updated every few iterations, depending on the magnitude of forces.
% After the indexing, a cubic cell with side $ar_L$ contains $O(a^3)$ link segments in the worst case. 
We only need to calculate forces in cells that contain more than one link.
We also shift the cells randomly for each indexing event to remove biases at the cell walls. 


In the weak phase using cells speeds up calculations enormously, as the number of crossings is very few and so cells crossed by more than one link are very few. 
Thus the total complexity will be either $O(N^2)$ from brute-force node repulsion or $O(sL)$ from indexing link segments and elastic forces, depending on which one is bigger.
In the strong phase, the links are filling the space.
But, as links can shrink and stretch, both with no link self-repulsion (Eq.(1)) and the double-ellipsoid potential (SI C. Eq.(32)) the number of link segments within one cell can vary from $1$ segment per cell to $O(s)$ per cell in the worst case.
A cell of size $ar_L$ contains a maximum of $O(a^3)$ distinct links. 
%Since links can shrink and stretch, the number of segments of each link that falls in each cell can vary. 
% In the best case, a cell has $1$ segment per link, and in the worst case it contains all $s$ segments.
Thus, in the worst case one cell may have $O\pr{(sa^3)^2}$ pairs of interacting link segments. 
The number $n_a$ of spatial cells with links crossing through them can be estimated from the size of the layout. 
The cross-section of all the links when the layout has opened up is $R\sim L^{1/2} r_L$ and so dividing by the cell size $ar_L$, the number of cells becomes $n_a \sim O\pr{\pr{L^{1/2}/a}^3}$. 
Therefore, the worst case time complexity is 
\[n_a O\pr{(sa^3)^2} \sim  O\pr{{ s^2 a^3  L^{3/2} } } \]
In practice, because the number of pairs $s^2 a^6$ in a cell may become large, we randomly sample up to a maximum number of pairs $\sim \max (100, s^2 a^3)$ in each cell to calculate the repulsive forces and the elastic forces help move the rest of the link segments to the correct positions. 
This way, for large networks the complexity is mostly due to number of cells $O(L^{3/2}/a^3)$.

% Our algorithm starts with a minimum number of cells $k$ and switches to cells of fixed size $ar_L$ once the network has opened up enough so that more than $k$ cells are occupied by more than one link. 


Discussion of the computational complexity is crucial for assessing the feasibility of any algorithm and we thank the referee for bringing this up. 
We will definitely extend SI 8.C to include the above.
This discussion is also useful for understanding the structure of  simulation code and the choices made therein.
The simulation code may achieve an even better time complexity by making use of a Binary Space Partitioning, such as a k-d tree, replacing the uniform cells that we have currently implemented.

% This reduces the complexity significantly (SI 8.C). 
% Arguably the most efficient partitioning %for this kind of interactions is 
% uses a k-d tree, which is a hierarchical binary space partitioning. 
% In our code, we use a fixed size for all partitions, but randomly shift the partitions to capture link segment pairs which may be close but had fallen in different partitions in the previous steps. 
% The partitioning does not need to be updated at each iteration, rather every 50-100 steps, generally. 

%We can certainly include these time complexity estimates for the strongly interacting phase in the SI or main text.
%{\color{red} Binary Space Partitioning, k-d tree complexity.}
\end{response}
\begin{response}{
3) Random geometric graphs are actually geometrical networks including a lot of link crossings. I imagine that one could observe a difference between the phase transition between the weak-interacting phase and the strong interacting phase for random geometric graphs in 2D or in 3D. My intuition is that for 3D random geometric graphs well deep in the percolation phase maybe the weak interacting phase disappear or else is significantly reduced. However for random geometric networks in 2D it is more easy to use the third dimension of the physical embedding to avoid crossings. 
}

This is an interesting scenario. 
Note that a random geometric graph (RGG) in 3D shares some characteristics of a force-directed layout (FDL) of an Erd\"os-Renyi (ER) random graph: 
1) in both networks nodes have a peaked degree distribution, thus nodes have similar degrees and have similar density of links around them; 2) in FDL nodes that are connected are on average closer to each other than disconnected nodes, similar to an RGG (One can argue that any ER graph is a RGG in $N-1$ dimensional space). 
Since our analysis shows that (Eq.(4)) the density of links is the important factor in the phase transition, we expect 3D RGG to behave similar to ER. 
For a 2D RGG, if the referee is asking about a 2D RGG with nodes fixed in a 2D plane inside 3D space, we do believe that phase transition will be slightly altered. 
The assumption of Eq.(4) is that nodes and links are distributed either randomly in space or based on FDL, which utilizes all three dimensions. 
Restricting the nodes to 2D would result in many link crossings even at very small $r_L$. 
As a result, the weak phase may disappear entirely. 
{\color{red}\bf  Find full phase space of 2D and 3D RGG}

The referee is pointing out an important aspect of our model. 
When the symmetries of 3D space are restricted, for instance by restricting nodes to a 2D subspace, the transition point may be affected. We are adding an explanation in the text, clarifying the underlying assumptions for Eq.(4) to be valid.
% Another aspect of these assumptions

% There are multiple, interesting scenarios that may pertain to the referee's question. 
% If the referee is assuming we start from a 2D random geometric graph (RGG), laid out on a plane, and then use our ELI algorithm in 3D to resolve its crossings while keeping nodes fixed, then, yes. 
% There would not exist any weakly interacting phase, as a large number of links have conflicts from the beginning. 
% {\color{red} TEST!!! This would arise from the  unusual symmetry of this setting}
% Note that in 2D any non-planar graph will have unresolvable link crossings. 
% This will include random geometric graphs. 
% So, in this sense, the referee's intuition is correct and the weakly interacting phase essentially disappears deep in the percolation phase. 
% %But, maybe the referee's question is about embedding a 2D random geometric graph in 3D, or ? 
% However, if you are asking whether for a 3D random geometric graph the weakly interacting phase disappears, we would argue that it does not. 
% %{\color{red} ER $\sim$ geometric, but not in 3D necessarily! show plots and sims!}

% Note that any force-directed layout (FDL) puts connected nodes closer to each other than non-connected nodes, which is also the formation criterion for a random geometric graph. 
% Thus, any FDL is equivalent to a random geometric graph which starts from a non-uniform spatial distribution of nodes.
% On the other hand, Erd\"os-Renyi (ER) random graphs have peaked degree distribution similar to random geometric graphs and FDL results in fairly uniform distribution of nodes in space (One could argue that any ER graph is a random geometric graph, just in a high dimensional space).  
% Based on this, 3D random geometric graphs must behave similar to random graphs. 

\end{response}

\newpage

\Reviewer{\#2}
\begin{response}{The authors examine the implications of spatial constraints (non crossing conditions of links and nodes) on the topology of networks embedded in a 3-dimensional space. 
Their main finding is that, depending on the link thickness ($r_L$), there exists two different phases with different geometrical properties, separated by a second order phase transition point occurring at a critical value $r_c$, which is approximated analytically. 
Physical properties of the network are shown to be substantially different in the two phases, and universality is claimed at the critical point. 
}

We thank the referee for their enlightening comments. 
\end{response}


\noindent
Main points:
\begin{response}{
1) The main analytical result of this work is the estimation of the critical radius in Eq.(4). 
The simple argument given in the main text is not satisfactory. 
The argument given by the authors disregards completely the heterogeneity in the density profiles of nodes and links, which are instead assumed to be uniform over the space. 
For example, in a scale free network, the density of links will be much higher near a hub node than low degree nodes, and these fluctuations may be strong enough to invalidate the argument used to derive Eq.(4), which assumes the same density around every node...

}

The referee brings up a key point: how does heterogeneity affect the phase transition? 
% First, note that the estimation of the phase transition point is done up to numerical factors that will depend on the details of the network architecture.
% As you correctly point out, heterogeneity of the network will affect it, but not the way you describe it. 
%The underlying reason is that heterogeneous degree distribution does not guarantee that force-directed layouts (FDL) result in inhomogeneous spatial density of nodes. 
To discuss this, we first have to establish what we mean by ``near a hub'', i.e. we need to define the size of the neighborhood.
To capture statistical properties of the layout the size of the neighborhood needs to be at least large enough to capture all links coming out of any node. 
In particular, the neighborhood size should be able to capture all links of a hub, as these links are interacting with each other and a neighborhood that captures only part of this interaction cannot describe a potential phase transition correctly. 
As we explain in SI 7.A, a degree $k$ node in a an unweighted network will have overlapping links up to radius $r_0\sim \sqrt{k} r_L/2 $. 
Thus, the neighborhood size must have radius larger than $r_0$. 
To measure heterogeneity, we must fix the neighborhood size and measure the link density in different parts of the network. 
Therefore, we choose the neighborhood radius to be $r_0\sim \sqrt{k_{\max}} r_L  $, where $k_{\max}$ is the maximum degree in the network. 
When $r_L/r_N$ is small, neighborhoods of size $r_0$ mostly consists of the node itself and the links connected to it. 
Thus, for small $r_L/r_N$ density of links around hubs will be larger and there will in general be a strong correlation between degree and link density. 
For large $r_L/r_N$, however, this heterogeneity becomes weaker. 

\textbf{Figure \ref{fig:neigh}} shows the properties of the number of links in the vicinity of a node for a scale-free (Barabasi-Albert) network and a random (Erd\"os-Renyi) network, both with $N=100, L=197$. 
We are not running the full algorithm, rather we are using the Force-directed Layouts (FDL) with straight links to measure the density of links. 
As we see, the coefficient of variation $\sigma/\mu$ (\textbf{Figure \ref{fig:neigh}}, right) of the number of links in the neighborhood of different nodes is high below the transition point, meaning heterogeneity in density is considerable. 
However, this heterogeneity  drops quickly after the transition.  
The correlation between degree and number of links in the neighborhood of a node (\textbf{Figure \ref{fig:neigh}}, left) drops sharply in the scale-free  network near our predicted transition point. 
Thus, near the transition point, a reasonably large neighborhood of nodes shows only a weak correlation between link density and node degree in a scale-free network.
We may, therefore, ignore the heterogeneity in link density near or above the transition point. 
The reason for this sharp drop in heterogeneity is that low degree nodes are mostly connected to hubs and so a reasonably large neighborhood of any low-degree node contains a hub and the large number of links connected to it. Thus, the density of links becomes similar among hubs and low-degree nodes at such radii.  

The random network also exhibits a drop in this correlation around the transition point, but maintains a high correlation between the degree and the number of neighborhood links up to very high $r_L/r_N$. 
Of course, since the overall variation in degree in ER is small, this correlation does not signify a large heterogeneity in the density of links around nodes, and the density of the links is fairly homogeneous over space. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=.45\textwidth]{fig-09-19/corr-deg-neigh.png}\includegraphics[width=.45\textwidth]{fig-09-19/coeff-var-neigh.png}
    \caption{{\bf Spatial heterogeneity of number of links in the neighborhood of nodes: }
    Correlation between degree and number of links in a neighborhood of radius $r_0\sim \sqrt{k_{\max}} r_L  $ of nodes in a scale-free and a random graph (Left) laid out using FDL (without links avoiding crossing) shows that the link density is correlated in with the degree. 
    But the correlation falls sharply above the transition point (red vertical band) in the scale-free network (blue curve).
    Thus, heterogeneity in link density becomes very weak near the phase transition and we can neglect it over a large region of the network.
    }
    \label{fig:neigh}
\end{figure}

Additionally, we would like to point out that Force-directed Layouts (FDL) are known to be equivalent to modularity clustering \cite{noack2009modularity}. 
Modularity $A_{ij}- k_ik_j/\pr{2\sum_l k_l}$, like degree assortativity, is a  second-order moment of the adjacency matrix and is not related to degree distribution. 
%It is well-known that Scale-free networks such as Barabasi-Albert have zero degree assortativity. 
Barabasi-Albert (BA) scale-free networks have vanishingly small modularity because they are ultra-small world and their degree assortativity is also zero. 
In particular, first order moments of the network, such as degree of nodes, does not result in the kind of heterogeneity in the density of links that would affect the transition point.
Having two modules with vastly different average degrees (e.g. two ER networks with different average degree connected to each other via a few links), however, does result in a  heterogeneity of link density which persists all the way until the neighborhood radius $r_0$ becomes comparable to the total layout radius. This kind of heterogeneity will change the behavior of the transition point.   
\outNim{
Consider a ball around a degree 1 node in a scale-free network. 
This node is most likely connected to a hub and the ball will therefore likely to contain the hub and other links connected to it.
This means that degree alone will not result in strong heterogeneity in the density of links. 
Also, note that, as we explain in SI 7.A, a degree $k$ node in a an unweighted network will have overlapping links up to radius $r_0\sim \sqrt{k} r_L/2 $ and to talk about the neighborhood of the node we have to talk about a region with radius larger than $r_0$.


Using FDL, inhomogeneous spatial node density only occurs in modular networks, not in scale-free networks. 
To see this, consider any low degree node in a scale-free network. 
We want to know if the links around it have lower density than around a high degree node. 
Take any link from a low-degree node.
In a scale-free network, the link is much more likely to be connected to a high degree node than a low degree node. 
Therefore the density of links around low degree nodes is practically the same as the density of links around high degree nodes, because neighbors of low degree nodes are mostly hubs.
There are no low density regions in a BA scale-free graph: the whole graph is mostly low-degree nodes connected to hubs. 
A random graph will clearly have a mostly uniform node distribution in space (except near boundaries of course), as all nodes look the same.
A highly modular network may undergo multiple transitions (this is the topic of our followup work). 
Of course, there can be modular graph  which are also approximately scale-free, in which case the referee's point would be valid.
More follows below. 
} 

\end{response}
\begin{response}{
\dots 
For example, in a scale free network with degree exponent $\gamma=2$, all links are basically 
attached to a single node (i.e. the node with largest degree), while in a 3D lattice they are evenly distributed across all nodes. Therefore, I do not see how the critical value $r_c$ cannot be sensitive to the value of the degree exponent $\gamma$, and thus on the network topology. Since the authors claim a "deep" universality, their main analytical finding Eq.(4) does not follow from this claim.

}
Although, degree exponent alone, or being a lattice does not affect the transition, the referee raises a very important point which needs a careful answer.
A simple counter-example which shows Eq.(4) needs slight modification is the case of having two identical disconnected random graphs with $N$ nodes and $L$ links. 
According to Eq.(4), for each one of these the transition occurs at $\tilde{r}_c$. 
Obviously when the two netwrks are disconnected, the transition still occurs at $\tilde{r}_c$, but Eq.(4) predicts a different transition at $2^{-1/6}\tilde{r}_c$, which is clearly wrong. 
The reason for this is basically due to the point the referee is making, that the transition depends n local density. 
Following our answer to the previous question,  the real units that should be used in Eq.4 are the smallest ``modules'' in the network, similar to unit cells of a lattice.
In fact, Eq.(4) also fails if we consider lattices of different size.
%For a cubic lattice the transition occurs when $r_L\sim r_N $. 

{\color{red} To be continued...}

Let us work on a specific example based on the referee's proposal.
consider a star network: 
Node 1 is at the center and all other $N-1$ nodes are only connected to node 1. 
Note that we have a short-range repulsion between nodes, independent of their degree, resulting in exclusion radius $r_N$ around each node. 
The tightest way to pack the $N$ nodes of this star network is a 3D close-packing of spheres, which results in a radius $R_N\sim N^{1/3}r_N$.
We have $L=N-1$ links going out at all angles but also ending on the nodes.
Let us calculate the average link length to see how much volume these link with thickness $r_L$ occupy. 
The mean link radius is simply the average of node location in a sphere of radius $R_N$ 
\[R_L =  \frac{4\pi \int_0^{R_N} r^3dr }{\int_0^{R_N} 4\pi r^2 dr} = {3\over 4} R_N \]
Therefore the total volume of links will be $V_L = \pi L r_L^2 R_L \approx 3\pi/4 L R_N r_L^2 $ when this volume is comparable to the total node volume $V_N = 4\pi/3 R_N^3$, the number of links pressing against each other becomes substantial and the phase transition occurs when
%
\[ {r_L\over r_N} = {3\over 4} N^{1/3}L^{-1/2}\]
%
Of course, the node layout that FDL will find won't be a perfect close-packing of spheres, but it will come close to it.
So, as expected, up to the numerical factor of $4/3$ our prediction for the phase transition is seems correct.

{\color{red} To be continued...}


\outNim{
The resolution is to use $N$ and $L$ of the 

What does matter is the size of the network and Eq.(4) is inaccurate unless we clarify the following. 
The main assumption of Eq.(4) is that the average length of links $R_L$ in any large region of the layout is the same. 
The accurate derivation of Eq.(4) comes from equating the total node volume $V_N \sim N r_N^3$ with the total link volume $V_L \sim R_L r_L^2$. 
Eq.(4) assumes that $R_L = c r_N $ is comparable to the layout radius. 
{\color{red}But this clearly fails in a 3D lattice and  geometric graphs. Talk about smallest unit cell that is repeated in these networks. The unit cell is what determines $N$ and $L$ to be used in Eq.(4). This will also solve the scaling issue.  }  
Eq.(4) predicts a transition when 
\[ \tilde{r}_c = {r_L\over r_N} = N^{1/3}L^{-1/2}\]
This would mean that if we double the number of nodes and links the transition would occur at $2^{-1/6} \tilde{r}_c$. 
However, in the weak phase a perfect cubic 3D lattice has $R_L=2r_N$ everywhere, regardless of the size of the lattice.
In a random graph, $R_L$ should grow uniformly with the layout radius, which itself grows with $N^{1/3}$ so $\tilde{r}_c$ does change. 


For the case of a lattice, in the perfect layout (i.e. lattice with no defect) the average link length is $R_L = 2r_N$. 
The number of links per node is $1$, so $L=N$. 
But this time, the average volume per each node is a cube of volume $r_N^3$ and the average volume excluded by each link not a cylinder, but a cuboid of volume $R_Lr_L^2$. 
Therefore, the link and node volumes become comparable when the thickness $r_L = r_N$ which is compatible with 
\[{r_L\over r_N} = \]
}


\end{response}
\begin{response}{
2) Is the model in Eq.(1) a new model or has been already used in the literature? In the latter case, please provide a reference for the model Eq.(1). 
}
It is a new model. 
Without $V_{LL}$ and replacing $V_{el}$ with the elastic energy of a spring yields the potential for a Force-directed layout with short-range node repulsion.  
\end{response}
\begin{response}{
3) What does it mean "the lowest energy solution of (1)"? Equation (1) is just the definition of the potential energy. Perhaps the authors meant the solution to the equation grad V = 0. Is that right?
}
No, we mean lowest energy state of the potential. 
Similar to FDL, the premise is that we want to minimize distance of nodes that are connected to each other while avoiding node and link crossing. 
Long links have a large elastic energy $V_{el}$, and crossing nodes and links have high values of $V_{NN}$ and $V_{LL}$ respectively. 
Thus, the configuration with minimum $V$ is the most desirable one. 

The procedure we use to find the minimum is gradient descent with noise (simulated annealing, Eqs.(2,3)), which does find a local minimum which satisfies $\del V = 0$. 
But it also escape local minima with high $V$ due to the noise. 
\end{response}
\begin{response}{
4) The data collapse in Fig.1G looks quite poor, and the use of a log scale on the y-axis is misleading? I do not think this result can be taken as a confirmation of the scaling relation Eq. (4). 
}
\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{fig-09-19/trans-collapse-dlog.png}
    \includegraphics[width=\textwidth]{fig-09-19/trans-collapse-dlog2.png}
    \caption{{\bf The slope of the average link length:} Top shows the derivative of average link length $\be{l}$ with respect to $\log(r_L/r_N)$. 
    As we see, without rescaling (top left) the curves for different network sizes and topologies follow different trajectories. 
    After rescaling by the predicted scaling of the transition point (top right), all the curves collapse to a single curve. 
    Note the y-axis is in linear scale. 
    Also, note that the slope is zero and starts becoming nonzero after the transition point. 
    The bottom plots show the slope of the logarithms $d \log \be{l}/d \log (r_L/r_N)$. 
    Again, before rescaling (bottom left) they differ, but after rescaling (right) they mostly collapse onto a single curve.
    This plot (bottom right) also reveals that, although the log-log slope eventually reaches a universal constant for all of these networks, there is region around the predicted transition point where the slope is slowly increasing, possibly due to finite size scaling effects.  
    }
    \label{fig:collapse}
\end{figure}

Note the goal was to collapse the x-axis, which is where the transition occurs, not the y-axis which is the total size of the network and depends on the number of nodes and links. 
A more suitable order parameter was the slope of the total link length, which is zero in the weak phase and nonzero after the transition, as shown here in {\bf Figure \ref{fig:collapse}}. 
As we can see in top of {\bf Figure \ref{fig:collapse}} the slope with respect to log of $r_L/r_N$ does collapse very well to a single curve, without log-scale for y. 
The second row shows the log-log slope $d\log\be{l}/d\log(r_L/r_N)$, which also results in good collapse of curves and shows that the slope is zero below the transition and slowly moves to a positive constant after the transition region.   

We chose average link length to reduce the number of variables defined, but would be open to using the slope for Fig.1 F,G. 
\end{response}
\begin{response}{
5) The authors say that the average curvature remains constant in the weakly interacting regime. However, Fig.2C shows that it grows for the ELI model. How did they conclude that curvature remains constant in the weakly interacting regime of the ELI model?
}
This is a finite system and the finite size effects widen the transition point to a ``transition region'' which in Fig.2 extends from $x\sim 10^{-1}$ to $x\sim 5$. 
We discuss this below.
%{\color{red} Related to link crossing force compared to node repulsion (recall the mismatch in forces in the stress plot SI, Fig.12.)}
The behavior in this transition region is clearly different from the weak or strong regions and merits a separate discussion. 
We would gladly add a section either to the paper or the SI discussing this.
Thus, the weak region is only up to $x\sim 0.1$, and the curvature is constant there, both in ELI and FUEL.
% The actual strong region starts around $x>5$ and there the curvature of both ELI and FUEL is dropping linearly. 
% As the curvature of the links is the inverse of the radius of curvature.
% In the strong phase, while the curvature is dropping linearly, the size of the layout is growing linearly (the same way that the curvature of a growing balloon decreases as its size increases). 
% Thus, if we scale all layouts in the strong phase to the same size, they all will have the same curvature.
% We can add a figure showing this constancy of curvature 


 
\end{response}
\begin{response}{
6) the peak in the relaxation time is observed only for the FUEL model, but it does not appear in the ELI model (or, at least, there is too much noise to see a peak). 
Therefore, how the authors conclude that the ELI model undergoes a phase transition? 
}

We should have emphasized that {\em only FUEL will have a peak in relaxation time, not ELI}. 
This is because the peak occurs when the forces on link components balance out, resulting in very small forces and very slow dynamics. 
In the weak phase, the force that is stretching the link segments is the node repulsion in FUEL. 
In ELI, however, there is no node repulsion and instead the nodes are fixed in space. 
In FUEL in the weak phase, if two link press against each other, their end-nodes can move to quickly equilibriate the system. 
The major forces determining the dynamics are the node repulsion and the elastic forces. 
In ELI in the weak phase, the nodes won't move and the repulsion in the few link crossings is the main force determining the time scale. 
The repulsive forces continue 
While in FUEL the links can push the nodes apart and make change 
{\color{red} Complete: like static friction, ELI in weak phase provides just enough force at nodes to keep links stretched... }
\outNim{
As mentioned above in ``5)'', we have a ``transition region'' $\sim 10^{-1}<x<5$. 
This is also clear from the relaxation time plots Fig.2D, which show that the peak in relaxation time for FUEL extends from $x\sim 10^{-1}$ to $x\sim 5$.

ElI lacks such a peak (the reason discussed below), rather it shows a linear drop over the smae region $\sim 10^{-1}<x<5$ from a high and fairly constant relaxation time in the weak phase to a very small one in the strong phase. 
}

\end{response}
\begin{response}{
7) The 'strong' peak in the relaxation time can be hardly considered as strong. What is the size of the network used? Can the author further support the claim of a phase transition with additional analysis (e.g. a finite size effect analysis)?

}

This is a great idea. 
{\color{red} work out the finite-size scaling.}
\end{response}
\begin{response}{
8) How can this method be scaled for large networks? The networks shown are very small (N=20, 40, 100, 200). How can this method be used in practice with networks of thousands or million nodes? Simulating annealing does not seem to me a viable route. What is the scalable and efficient algorithm that can be used for larger networks. 
}
We are currently working on scaling the method up. 
Without any modification, a network with a few thousand links in the strong phase takes less than a week on a GPU. 
We can provide more details about the settings together with the simulation code at the referee's request. 

In the weak phase the full layout is a perturbation to FDL. 
Thus one can do a fast FDL first --ignoring the internal degrees of freedom of links-- and then run the full algorithm to resolve potential link crossings. 
This can be done for networks with thousands of nodes. 

Another avenue is that, for modular networks or networks with strong hierarchy one can exploit the hierarchy to lay the network out at multiple scales, thereby reducing the complexity of each run. 
For non-modular networks the best heuristic algorithm would be to use k-d tree to partition the space to and only resolve crossings within the partitions, because our forces are short-range. 
We are using a space partitioning in our simulation code as well. 
Beyond this, for non-modular networks the computation cannot be optimized much further other than large scale parallelization or using the GPU, also implemented in our code.


\end{response}
\begin{response}{
9) What is the role of the radius of nodes $r_N$? It looks like it does not play any role in the critical behavior of the model. 
}
The phases must be defined as function of a dimensionless parameter, such as $r_L/r_N$ to allow us to compare different networks. 
One may assume that instead of varying $r_L$ we are varying $r_N$, the results are equivalent. 

\end{response}
\begin{response}{
10) What is the role of the dimension of the space D? Does the transition disappears in the large D limit, where the non crossing conditions are no more a issue? Is the transition a genuine feature of a 3 dimensional embedding space?
}
We believe, yes, it is only a feature of 3D.
The dimensions do play a role as all the distances in Eq.(1), such as $|x_l-x_m|$ do generalize to $D$ dimensions. 
In $D$ dimensions the nodes have an exclusion region of the form of a $D$-dimensional sphere and the link cross-sections is $S_{D-1}$, the spherical shell, or boundary of a $D$-dimensional ball. 
The crossings, however, becomes related to the referee's question about the knots, because links are still effectively 1D.
If one considers two thin links, in $D>3$ they can always pass by each other. 
This is because if one considers the segment of links 1 and 2 near the crossing, the segment from link 1 can be embedded in the dimensions $x_1,x_2$, and the segment from link 2 in $x_3,x_4$. 
This makes links 1 and 2 invisible to each other and allows them to resolve the crossing by moving away from the crossing area (as the referee probably know, this is why knot theory for 1D curves only exists in 3D \cite{zeeman1963unknotting}, and in general knotted $n$-spheres can be untied in $n+2$ dimensions). 
So, the 3D is the lowest dimensions where any crossing can be resolved and also the highest dimension where it is a problem at all.  
\end{response}
\begin{response}{
11) Mammalian Brains: In the last paragraph of the article, the authors state that the methods offered a modeling framework to capture the layout geometry of dense neuronal networks. However, the model described in the article is different from actual neural networks. Although the neurons are densely packed, the length of axon is still much larger than the size of neuron. The evidence of length scale is not strong enough to support the statement. 


}
We did not want to go into the detail of this in the paper, but one has to think of the mammalian brain at a high level, taking large anatomical region as nodes, instead of individual neurons, and taking bundles of axons going from one region to another as links, instead of individual axons. 
It is well known that most axons in the white matter follow a trajectory that has already been established by the ``pioneer axons'' \cite{raper2010cellular}. 
Therefore, much of the white matter consists of large bundles of axons, not individual ones. 
There are between a dozen to a few hundred anatomical regions in the gray matter, depending on the scale considered.
At these scales the thickness of the white matter axon bundles connecting the regions becomes comparable to the size of the gray matter region.

We do agree that the scaling alone does not prove any relation. 
However, it is quite significant that our findings indicate that the primate brain {\em is not} compatible with the strong phase, whereas the rodent brain is. 

\end{response}

Minor points: 
\begin{response}{
12) Fig. 1D, E, F, G are called after Fig.2. 
}
Yes, we tried to find the best way to start talking about the phase transition and decided the best use of space for figures would be to group it in the first figure. 
We can certainly change that. 
\end{response}
\begin{response}{
13) Twists and Knots: In physical network, especially for weak interaction networks with length of link >> size of node, there will be a large probability that link will twists or even have knots. Such structures could largely affect the properties of network since in this case, the links are not weakly interacting anymore. 

According to the modeling framework, the annealing algorithm proposed will likely remove the existence of twists and knots by the introduction of local approximation and thermo-noise. How the algorithm affects the topology of the resulting network? For example, start with a simple loose structure with knots or twists between links and see how the topology changed according to different level of noise or thickness of links. Or explain the limitations of the model if it is hard to simulated the network with topological complexity.
}

Very good point. 
We have indeed worked on this, but did not see it fit for the paper. 
We intend to write a separate paper discussing the rich space of topological states that com of this model. 

The short answer is, in a truly continuous link with infinite hard-core repulsion there is no way to resolve the knots, nor is it possible for links to pass through each other to find more favorable configurations. 
What we have done with Eq.(1) is that we made the repulsive forces smooth, analytical functions with finite maximum repulsive force. 
This allows nodes and links to tunnel through each other and with a suitable amount of thermal noise.
However, when the noise amplitude is large (more than $r_L$) and the annealing schedule is such that the noise persists for a long time (comparable to the expected relaxation time), we do get many twists and knots. 
In addition to this, we observe the equivalent of ``kinks'' and ``solitons'', best observed when laying out 3D lattices (figure \ref{fig:twist} here).
\begin{figure}[ht]
    \centering
    \includegraphics[width=.8\textwidth]{fig-09-19/3D-twist.pdf}
    \caption{{\bf Solitonic solutions:} A frequent outcome of laying out networks with discrete symmetries, such as 3D lattices due to reflection symmetry, is topological defects: the orientation of two ends of the lattice may be different (A, red arrows pointing to the fact that the orientation of the lattice along the y direction has switched from one end of the layout to the other), resulting in a twist in the middle of the layout. 
    (B) A clearer view of a twist in occurring in laying out a lattice. 
    Twists, like other solitonic solutions, are generally localized, increasing total link lengths only by a small amount. 
    As a result, these solitonic solutions have energies close to the global minimum.
    They are encountered frequently during simulated annealing because of their high degeneracy: the twist may occur anywhere in the lattice and its energy is related to its size. 
    }
    \label{fig:twist}
\end{figure}
The underlying reason is the same as regular solitons: there exist multiple global minima for $V$ which are related to each other via discrete symmetries, such as reflection in the $x$ direction. 
During the dynamics one side of the network may fall into one minimum configuration and the other side into the reflected configuration, resulting in a twist somewhere in the layout. 
These solitonic solutions are still low energy solutions. 
Even though they are not a global minimum, their energy is close to the global minimum and their number is more plentiful than the global minima because of the combinatorics. 
In fact, most layouts of the 3D lattice, including the ones used for Fig.2 turn out to have such twists, but in the log-scale, $\be{l}$ and curvature seem to be similar among them, suggesting that they belong to approximately degenerate energy states. 
We would be happy to discuss this further. 

\end{response}
\begin{response}{
15) Distribution of link length or curvature. Average link length is an important order parameter of phase transition. Instead of characterizing the order transition by a simple average, I suggest the authors to investigate the change of distribution of link length which will provide more details about how the transition happened.
}
This is an interesting proposal. 
We did look at distributions of forces in relation with the stress, but they differ across different topologies in the weak exclusion phase.
We couldn't find a reasonable universal measure that works across different topologies and at the same time found that the phase behavior had almost no dependence on the topology. 

\end{response}



\bibliographystyle{plain}
\bibliography{mybib}
\end{document}